{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up8g8-keaxO8",
        "outputId": "d1976466-1ee9-42bb-b49e-1b3df2b837ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hC4x_jtvmBCu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random\n",
        "import cv2\n",
        "import glob as gb\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, Conv1D, MaxPool1D\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, concatenate\n"
      ],
      "metadata": {
        "id": "uUXGbIuBmBH7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData=[]\n",
        "trainLabels=[]\n",
        "\n",
        "for root, _, files in os.walk('/content/drive/MyDrive/DatasetMain-20240306T050200Z-001/Data4/Training/notumor'):\n",
        "  for file in files:\n",
        "    if file.endswith('.jpg'):\n",
        "      image_path = os.path.join(root,file)\n",
        "      if 'notumor' in image_path:\n",
        "        label = 0\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image_array = np.array(image)\n",
        "        trainData.append(image_array)\n",
        "        trainLabels.append(label)\n",
        "        #print(f\"Image Path: {image_path}, Label: {label}\")\n",
        "for root, _, files in os.walk('/content/drive/MyDrive/DatasetMain-20240306T050200Z-001/Data4/Training/glioma'):\n",
        "  for file in files:\n",
        "    if file.endswith('.jpg'):\n",
        "      image_path = os.path.join(root,file)\n",
        "      if 'glioma' in image_path:\n",
        "        label = 1\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image_array = np.array(image)\n",
        "        trainData.append(image_array)\n",
        "        trainLabels.append(label)\n",
        "        #print(f\"Image Path: {image_path}, Label: {label}\")\n",
        "for root, _, files in os.walk('/content/drive/MyDrive/DatasetMain-20240306T050200Z-001/Data4/Training/pituitary'):\n",
        "  for file in files:\n",
        "    if file.endswith('.jpg'):\n",
        "      image_path = os.path.join(root,file)\n",
        "      if 'pituitary' in image_path:\n",
        "        label = 2\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image_array = np.array(image)\n",
        "        trainData.append(image_array)\n",
        "        trainLabels.append(label)\n",
        "        #print(f\"Image Path: {image_path}, Label: {label}\")\n",
        "for root, _, files in os.walk('/content/drive/MyDrive/DatasetMain-20240306T050200Z-001/Data4/Training/meningioma'):\n",
        "  for file in files:\n",
        "    if file.endswith('.jpg'):\n",
        "      image_path = os.path.join(root,file)\n",
        "      if 'meningioma' in image_path:\n",
        "        label = 3\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image_array = np.array(image)\n",
        "        trainData.append(image_array)\n",
        "        trainLabels.append(label)\n",
        "        #print(f\"Image Path: {image_path}, Label: {label}\")"
      ],
      "metadata": {
        "id": "2TE9GF_JmBQK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testData=[]\n",
        "testLabels=[]\n",
        "\n",
        "for root, _, files in os.walk('/content/drive/MyDrive/DatasetMain-20240306T050200Z-001/Data4/Testing/notumor'):\n",
        "  for file in files:\n",
        "    if file.endswith('.jpg'):\n",
        "      image_path = os.path.join(root,file)\n",
        "      if 'notumor' in image_path:\n",
        "        label = 0\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image_array = np.array(image)\n",
        "        testData.append(image_array)\n",
        "        testLabels.append(label)\n",
        "        #print(f\"Image Path: {image_path}, Label: {label}\")\n",
        "for root, _, files in os.walk('/content/drive/MyDrive/DatasetMain-20240306T050200Z-001/Data4/Testing/glioma'):\n",
        "  for file in files:\n",
        "    if file.endswith('.jpg'):\n",
        "      image_path = os.path.join(root,file)\n",
        "      if 'glioma' in image_path:\n",
        "        label = 1\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image_array = np.array(image)\n",
        "        testData.append(image_array)\n",
        "        testLabels.append(label)\n",
        "        #print(f\"Image Path: {image_path}, Label: {label}\")\n",
        "for root, _, files in os.walk('/content/drive/MyDrive/DatasetMain-20240306T050200Z-001/Data4/Testing/pituitary'):\n",
        "  for file in files:\n",
        "    if file.endswith('.jpg'):\n",
        "      image_path = os.path.join(root,file)\n",
        "      if 'pituitary' in image_path:\n",
        "        label = 2\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image_array = np.array(image)\n",
        "        testData.append(image_array)\n",
        "        testLabels.append(label)\n",
        "        #print(f\"Image Path: {image_path}, Label: {label}\")\n",
        "for root, _, files in os.walk('/content/drive/MyDrive/DatasetMain-20240306T050200Z-001/Data4/Testing/meningioma'):\n",
        "  for file in files:\n",
        "    if file.endswith('.jpg'):\n",
        "      image_path = os.path.join(root,file)\n",
        "      if 'meningioma' in image_path:\n",
        "        label = 3\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image,(224,224))\n",
        "        image_array = np.array(image)\n",
        "        testData.append(image_array)\n",
        "        testLabels.append(label)"
      ],
      "metadata": {
        "id": "0zOt5GB4o8U5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "X_train = trainData\n",
        "y_train = trainLabels\n",
        "X_test = testData\n",
        "y_test = testLabels\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=4)\n",
        "y_test = to_categorical(y_test, num_classes=4)\n",
        "\n",
        "X_val, X_test = train_test_split(X_test, train_size=.3, random_state=20)\n",
        "y_val, y_test = train_test_split(y_test, train_size=.3, random_state=20)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_val = np.array(y_val)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)\n",
        "\n",
        "\n",
        "print(f\"Shape of images in X_train: {X_train.shape}\")\n",
        "print(f\"Shape of images in X_test: {X_test.shape}\")\n",
        "print(f\"Shape of images in X_val: {X_val.shape}\")\n",
        "print(f\"Shape of images in y_train: {y_train.shape}\")\n",
        "print(f\"Shape of images in y_test: {y_test.shape}\")\n",
        "print(f\"Shape of images in y_val: {y_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVoMNE15o8hi",
        "outputId": "acfa2a41-6e33-4e5d-96a9-12297f6c75b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images in X_train: (5736, 224, 224, 3)\n",
            "Shape of images in X_test: (918, 224, 224, 3)\n",
            "Shape of images in X_val: (393, 224, 224, 3)\n",
            "Shape of images in y_train: (5736, 4)\n",
            "Shape of images in y_test: (918, 4)\n",
            "Shape of images in y_val: (393, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "metadata": {
        "id": "Nyt5FmMu3ObG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Set Shape after preprocesssing = \",X_train.shape)\n",
        "print(\"Validation Set Shape after preprocesssing= \",X_val.shape)\n",
        "print(\"Test Set Shape after preprocesssing= \",X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtIXBhu025d3",
        "outputId": "5b61ad5e-ba2d-42f3-a68f-a31b16092aa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Shape after preprocesssing =  (5736, 224, 224, 3)\n",
            "Validation Set Shape after preprocesssing=  (393, 224, 224, 3)\n",
            "Test Set Shape after preprocesssing=  (918, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1024,activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1024,activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4,activation='softmax')\n",
        "\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "y7_lxdoC3Y9P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n"
      ],
      "metadata": {
        "id": "kCe8SbsocAsL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    Conv2D(filters=64, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    Conv2D(filters=192, kernel_size=(5, 5), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    Conv2D(filters=384, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    # Flatten the output of CNN layers before passing it to GRU\n",
        "   # Flatten the output of CNN layers before passing it to GRU\n",
        "# Flatten the output of CNN layers before passing it to GRU\n",
        "keras.layers.Reshape((-1, 128)),\n",
        "    GRU(128),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "gdRXCtuHbBnz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer ='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HJ72FgsF3cAM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop= EarlyStopping(monitor='val_loss',patience=2)"
      ],
      "metadata": {
        "id": "wyN-zXzr3fGJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                            patience=2,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.001)"
      ],
      "metadata": {
        "id": "rJnbKZrr3ifT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "epochs =40\n",
        "ThisModel = model.fit(X_train,y_train,epochs=epochs,validation_data = (X_val,y_val),batch_size=64,verbose=2,callbacks=[learning_rate_reduction])\n",
        "print(\"Total time: \", time.time() - start, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmDpSyBR3k_v",
        "outputId": "ca010754-e216-4e89-b2c2-ce79938b1bef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "90/90 - 4s - loss: 0.0933 - accuracy: 0.9716 - val_loss: 0.1938 - val_accuracy: 0.9542 - lr: 0.0010 - 4s/epoch - 45ms/step\n",
            "Epoch 2/40\n",
            "90/90 - 4s - loss: 0.0924 - accuracy: 0.9709 - val_loss: 0.1270 - val_accuracy: 0.9746 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 3/40\n",
            "90/90 - 4s - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.1846 - val_accuracy: 0.9542 - lr: 0.0010 - 4s/epoch - 40ms/step\n",
            "Epoch 4/40\n",
            "90/90 - 4s - loss: 0.0786 - accuracy: 0.9766 - val_loss: 0.1433 - val_accuracy: 0.9746 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 5/40\n",
            "90/90 - 4s - loss: 0.0821 - accuracy: 0.9745 - val_loss: 0.6307 - val_accuracy: 0.8601 - lr: 0.0010 - 4s/epoch - 44ms/step\n",
            "Epoch 6/40\n",
            "90/90 - 4s - loss: 0.0971 - accuracy: 0.9697 - val_loss: 0.1248 - val_accuracy: 0.9695 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 7/40\n",
            "90/90 - 4s - loss: 0.0955 - accuracy: 0.9707 - val_loss: 0.2152 - val_accuracy: 0.9262 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 8/40\n",
            "90/90 - 4s - loss: 0.1632 - accuracy: 0.9517 - val_loss: 0.7003 - val_accuracy: 0.8168 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 9/40\n",
            "90/90 - 4s - loss: 0.2101 - accuracy: 0.9383 - val_loss: 1.2768 - val_accuracy: 0.7023 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 10/40\n",
            "90/90 - 4s - loss: 0.3125 - accuracy: 0.8947 - val_loss: 1.8981 - val_accuracy: 0.6209 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 11/40\n",
            "90/90 - 4s - loss: 0.1865 - accuracy: 0.9421 - val_loss: 0.2418 - val_accuracy: 0.9109 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 12/40\n",
            "90/90 - 4s - loss: 0.1602 - accuracy: 0.9503 - val_loss: 0.1997 - val_accuracy: 0.9338 - lr: 0.0010 - 4s/epoch - 43ms/step\n",
            "Epoch 13/40\n",
            "90/90 - 4s - loss: 0.1469 - accuracy: 0.9587 - val_loss: 0.5387 - val_accuracy: 0.8702 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 14/40\n",
            "90/90 - 4s - loss: 0.1428 - accuracy: 0.9562 - val_loss: 0.4249 - val_accuracy: 0.8651 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 15/40\n",
            "90/90 - 4s - loss: 0.1822 - accuracy: 0.9460 - val_loss: 0.8430 - val_accuracy: 0.7430 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 16/40\n",
            "90/90 - 4s - loss: 0.1944 - accuracy: 0.9388 - val_loss: 1.3214 - val_accuracy: 0.6692 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 17/40\n",
            "90/90 - 4s - loss: 0.1944 - accuracy: 0.9367 - val_loss: 0.2162 - val_accuracy: 0.9262 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 18/40\n",
            "90/90 - 4s - loss: 0.1497 - accuracy: 0.9554 - val_loss: 0.3111 - val_accuracy: 0.8880 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 19/40\n",
            "90/90 - 4s - loss: 0.1269 - accuracy: 0.9613 - val_loss: 0.2499 - val_accuracy: 0.9288 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 20/40\n",
            "90/90 - 4s - loss: 0.1206 - accuracy: 0.9651 - val_loss: 0.2608 - val_accuracy: 0.9160 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 21/40\n",
            "90/90 - 4s - loss: 0.1254 - accuracy: 0.9618 - val_loss: 0.3708 - val_accuracy: 0.8550 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 22/40\n",
            "90/90 - 4s - loss: 0.1125 - accuracy: 0.9643 - val_loss: 0.1663 - val_accuracy: 0.9491 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 23/40\n",
            "90/90 - 4s - loss: 0.1038 - accuracy: 0.9676 - val_loss: 0.4680 - val_accuracy: 0.8753 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 24/40\n",
            "90/90 - 4s - loss: 0.1189 - accuracy: 0.9620 - val_loss: 0.4561 - val_accuracy: 0.8906 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 25/40\n",
            "90/90 - 4s - loss: 0.1223 - accuracy: 0.9630 - val_loss: 0.2855 - val_accuracy: 0.9059 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 26/40\n",
            "90/90 - 4s - loss: 0.0874 - accuracy: 0.9749 - val_loss: 0.1486 - val_accuracy: 0.9491 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 27/40\n",
            "90/90 - 4s - loss: 0.0867 - accuracy: 0.9759 - val_loss: 0.1410 - val_accuracy: 0.9618 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 28/40\n",
            "90/90 - 4s - loss: 0.1207 - accuracy: 0.9636 - val_loss: 0.7029 - val_accuracy: 0.8295 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 29/40\n",
            "90/90 - 4s - loss: 0.1368 - accuracy: 0.9616 - val_loss: 0.2269 - val_accuracy: 0.9389 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 30/40\n",
            "90/90 - 4s - loss: 0.1119 - accuracy: 0.9653 - val_loss: 0.2132 - val_accuracy: 0.9313 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 31/40\n",
            "90/90 - 4s - loss: 0.1048 - accuracy: 0.9698 - val_loss: 0.3179 - val_accuracy: 0.9135 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 32/40\n",
            "90/90 - 4s - loss: 0.0970 - accuracy: 0.9718 - val_loss: 0.2011 - val_accuracy: 0.9466 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 33/40\n",
            "90/90 - 4s - loss: 0.1142 - accuracy: 0.9653 - val_loss: 0.1891 - val_accuracy: 0.9542 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 34/40\n",
            "90/90 - 4s - loss: 0.1201 - accuracy: 0.9629 - val_loss: 0.2178 - val_accuracy: 0.9313 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 35/40\n",
            "90/90 - 4s - loss: 0.1100 - accuracy: 0.9669 - val_loss: 0.4564 - val_accuracy: 0.8677 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 36/40\n",
            "90/90 - 4s - loss: 0.0854 - accuracy: 0.9761 - val_loss: 0.1436 - val_accuracy: 0.9669 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 37/40\n",
            "90/90 - 4s - loss: 0.0735 - accuracy: 0.9786 - val_loss: 0.1481 - val_accuracy: 0.9567 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 38/40\n",
            "90/90 - 4s - loss: 0.0780 - accuracy: 0.9777 - val_loss: 0.1815 - val_accuracy: 0.9491 - lr: 0.0010 - 4s/epoch - 41ms/step\n",
            "Epoch 39/40\n",
            "90/90 - 4s - loss: 0.0773 - accuracy: 0.9782 - val_loss: 0.3818 - val_accuracy: 0.9237 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Epoch 40/40\n",
            "90/90 - 4s - loss: 0.0573 - accuracy: 0.9843 - val_loss: 0.2270 - val_accuracy: 0.9364 - lr: 0.0010 - 4s/epoch - 42ms/step\n",
            "Total time:  152.30177330970764 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-6GmSOY7Mll",
        "outputId": "937f20cb-4061-4b4f-f0e4-ef77e08c118f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 14ms/step - loss: 0.2398 - accuracy: 0.9390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23984551429748535, 0.9389978051185608]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}